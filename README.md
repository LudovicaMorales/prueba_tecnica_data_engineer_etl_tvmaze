# Prueba T√©cnica Data Engineer ETL TVmaze

Este proyecto es una prueba t√©cnica para el cargo de Data Engineer donde se realizan operaciones de extracci√≥n, transformaci√≥n y carga (ETL) de informaci√≥n sobre shows de TV emitidos por web/streaming durante enero de 2024, haciendo uso de la API de TVMaze.

## Descripci√≥n del proyecto

Este proyecto implementa un pipeline ETL completo dentro de un entorno controlado y aislado mediante Docker, con Poetry para la gesti√≥n de dependencias y Makefile para simplificar la ejecuci√≥n de comandos.

## Objetivo Principal
Recopilar, procesar y analizar datos de series de TV emitidas por web/streaming durante enero de 2024 a trav√©s de la API de TVmaze.

## Tecnolog√≠as utilizadas
| Componente | Tecnolog√≠as |
|-----------|-------------|
| Entorno | Docker, Poetry, Makefile |
| Lenguaje de Programaci√≥n | Python |
| Extracci√≥n | Requests |
| Perfilado de Datos| ydata-profiling |
| Transformaci√≥n| Pandas |
| Almacenamiento | Parquet (compresi√≥n Snappy), JSON, SQLite |

## Estructura del proyecto

```
prueba_tecnica_data_engineer_etl_tvmaze/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                              # Almacenamiento de datos procesados
‚îÇ
‚îú‚îÄ‚îÄ üìÅ db/                                # Base de datos SQLite y archivos relacionados
‚îÇ
‚îú‚îÄ‚îÄ üìÅ json/                              # Archivos JSON resultantes
‚îÇ
‚îú‚îÄ‚îÄ üìÅ model/                             # Modelos de datos
‚îÇ
‚îú‚îÄ‚îÄ üìÅ profiling/                         # Informe y an√°lisis de perfilado de datos
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                               # C√≥digo fuente principal
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ tests/                         # Pruebas unitarias
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ mock_response.json         # Datos simulados para pruebas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ test_extraction.py         # Pruebas para el m√≥dulo de extracci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ test_load.py               # Pruebas para el m√≥dulo de carga
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ test_transform.py          # Pruebas para el m√≥dulo de transformaci√≥n
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ analysis.py                    # An√°lisis de datos y generaci√≥n de m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ extraction.py                  # M√≥dulo para extraer datos de la API
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ load.py                        # M√≥dulo para cargar datos procesados
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ main_etl.py                    # Punto de entrada principal del pipeline ETL
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ transform.py                   # M√≥dulo para transformar datos
‚îÇ
‚îú‚îÄ‚îÄ üìÑ .gitignore                         # Archivos y directorios ignorados por Git
‚îú‚îÄ‚îÄ üìÑ Dockerfile                         # Configuraci√≥n del contenedor Docker
‚îú‚îÄ‚îÄ üìÑ Makefile                           # Comandos para automatizar tareas
‚îú‚îÄ‚îÄ üìÑ poetry.lock                        # Bloqueo de dependencias espec√≠ficas
‚îî‚îÄ‚îÄ üìÑ pyproject.toml                     # Configuraci√≥n del proyecto y dependencias
```

## Instalaci√≥n

### Prerrequisitos

Antes de instalar el proyecto, aseg√∫rate de tener las siguientes herramientas en tu sistema:

| Herramienta | Funci√≥n | Obligatorio |
|-------------|---------|-------------|
| [Docker](https://docs.docker.com/get-docker/) | Contenedorizaci√≥n | ‚úÖ |
| [Make](https://www.gnu.org/software/make/) | Automatizaci√≥n | ‚≠ê Opcional |

> **Nota**: Make es opcional pero recomendado para simplificar los comandos. Se proporcionan alternativas con Docker puro.

### Pasos de Instalaci√≥n

#### 1Ô∏è‚É£ Clonar el repositorio

```bash
git clone https://github.com/LudovicaMorales/prueba_tecnica_data_engineer_etl_tvmaze.git

cd prueba_tecnica_data_engineer_etl_tvmaze
```

#### 2Ô∏è‚É£ Construir la imagen de Docker

**Con Make** (recomendado):
```bash
make build
```

**Solo con Docker**:
```bash
docker build -t prueba_tecnica_data_engineer_etl_tvmaze:latest .
```

#### 3Ô∏è‚É£ Ejecutar el proyecto

**Con Make** (recomendado):
```bash
make run
```

**Solo con Docker**:
```bash
docker run --rm -it -v $(PWD):/app --name prueba_tecnica_data_engineer_etl_tvmaze prueba_tecnica_data_engineer_etl_tvmaze:latest
```

### Verificaci√≥n

Tras ejecutar estos comandos, el proyecto comenzar√° autom√°ticamente a:

- Extraer datos de la API de TVmaze
- Transformar la informaci√≥n 
- Cargar los resultados en las ubicaciones correspondientes

Los archivos generados estar√°n disponibles en las carpetas `/json`, `/data`, `/db` y `/profiling` de tu directorio local.

### Comandos Adicionales

| Comando | Descripci√≥n |
|---------|-------------|
| `make shell` | Abre la terminal|
| `etl` | Ejecuta todo el flujo de la ETL|

## Descripci√≥n del c√≥digo

#### 1Ô∏è‚É£ Extracci√≥n (`extraction.py`)
- Realiza peticiones HTTP a la API de TVmaze para cada d√≠a de enero 2024
- Obtiene informaci√≥n de shows emitidos en plataformas web/streaming
- Almacena las respuestas en archivos JSON para procesamiento posterior

#### 2Ô∏è‚É£ Transformaci√≥n (`transform.py`)
- **Carga inicial**: Lee todos los archivos JSON y los unifica en un DataFrame de pandas
- **Limpieza de datos**:
  - Estandarizaci√≥n de nombres de columnas y formatos de fecha
  - Eliminaci√≥n de HTML en campos de texto como res√∫menes
  - Descarte de columnas con >85% de datos faltantes
  - Filtrado de registros espec√≠ficos (ej: temporada 2024)
  - Imputaci√≥n de valores num√©ricos faltantes usando la mediana
  - Imputaci√≥n de valores categ√≥ricos faltantes usando la moda
  - Normalizaci√≥n de listas (g√©neros, d√≠as de emisi√≥n) a cadenas separadas por comas
  - Mapeo de d√≠as de la semana a n√∫meros para facilitar an√°lisis
  - Normalizaci√≥n de categor√≠as poco frecuentes
  - Eliminaci√≥n de filas con <25% de datos completos
  - Eliminaci√≥n de duplicados

#### 3Ô∏è‚É£ An√°lisis (`analysis.py`)
- Generaci√≥n de perfiles de datos con `ydata-profiling` exportados en HTML
- C√°lculo de m√©tricas clave:
  - Runtime promedio de episodios
  - Distribuci√≥n de shows por g√©nero
  - Listado de dominios de sitios oficiales

#### 4Ô∏è‚É£ Carga (`load.py`)
- **Almacenamiento en Parquet**: 
  - Exportaci√≥n eficiente con compresi√≥n Snappy para an√°lisis r√°pido
  - Guardado en `/data` para acceso posterior
- **Base de datos SQLite**: 
  - Creaci√≥n de esquema relacional normalizado
  - Carga de datos procesados en tablas estructuradas
  - Almacenamiento en `/db` para consultas SQL

## Modelo de Datos

El modelo relacional implementado est√° dise√±ado para capturar y organizar eficientemente toda la informaci√≥n de programas de televisi√≥n obtenida desde la API de TVmaze. La estructura normalizada permite consultas optimizadas y mantiene la integridad de los datos.

![Modelo de Datos](./model/ERD tvmaze_data_db.png)

La imagen del modelo de datos se encuentra en la carpeta model/.

## Pruebas Unitarias

El proyecto incluye un conjunto completo de pruebas unitarias para verificar la funcionalidad de cada componente del pipeline ETL. Estas pruebas est√°n ubicadas en la carpeta `src/tests/` y aseguran la robustez del c√≥digo.

### Componentes Probados

| Componente | Archivo | Funcionalidad probada |
|------------|---------|----------------------|
| Extracci√≥n | `test_extraction.py` | Conexi√≥n con API y almacenamiento de datos |
| Transformaci√≥n | `test_transform.py` | Limpieza y procesamiento de datos |
| Carga | `test_load.py` | Exportaci√≥n a Parquet con compresi√≥n Snappy |

### Estrategias de Prueba Implementadas

#### Mocking y Simulaci√≥n
- Utilizaci√≥n de `unittest.mock` para simular respuestas de API
- Archivo `mock_response.json` con datos de ejemplo representativos
- Simulaci√≥n de errores de conexi√≥n para probar manejo de excepciones

#### Verificaci√≥n de Transformaciones
- Validaci√≥n de la conversi√≥n de fechas mediante `safe_to_datetime`
- Comprobaci√≥n de la limpieza de datos HTML en campos de texto
- Verificaci√≥n de la normalizaci√≥n de listas a formato de texto

#### Testing de I/O
- Uso de directorios temporales para pruebas de escritura de archivos
- Verificaci√≥n de compresi√≥n correcta en archivos Parquet
- Validaci√≥n de estructura de datos generados

### Ejecuci√≥n de Pruebas

Para ejecutar pruebas espec√≠ficas:

```bash
# Pruebas de extracci√≥n
python -m unittest src.tests.test_extraction

# Pruebas de transformaci√≥n
python -m unittest src.tests.test_transform

# Pruebas de carga
python -m unittest src.tests.test_load
```

### Cobertura de Pruebas

Las pruebas cubren los siguientes escenarios clave:

- Extracci√≥n exitosa de datos de la API de TVmaze
- Manejo de errores en la conexi√≥n con la API
- Creaci√≥n correcta de DataFrames desde archivos JSON
- Transformaci√≥n y limpieza de diferentes tipos de datos
- Almacenamiento en formato Parquet con compresi√≥n Snappy
- Validaci√≥n de la integridad de los datos procesados

Estas pruebas garantizan que el pipeline ETL funcione correctamente en diferentes escenarios y proporcione resultados consistentes.

### ¬°Muchas gracias por tu lectura y atenci√≥n! üíö
